{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "\n",
    "# 因为默认tf会吧全部显存都占用光, 所以在进行卷积计算的时候回报错提示无法初始化cuDNN, 所以这里我们需要手动的将tf设置成按需占用内存\n",
    "# 这样就避免了卷积计算错误的问题\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个ResNet的基本传递块\n",
    "class BasicBlock(keras.layers.Layer):\n",
    "    def __init__(self,filter_num,stride = 1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(filters = filter_num,kernel_size=(3,3),strides=stride,padding='SAME') # kernel的大小选3*3或者1*1都可以\n",
    "        self.bn1 = keras.layers.BatchNormalization() #这里是一个非线性层\n",
    "        self.relu = keras.layers.Activation('relu')\n",
    "        self.conv2 = keras.layers.Conv2D(filters=filter_num,kernel_size=(3,3),strides=1,padding='SAME')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        \n",
    "        if stride != 1:\n",
    "            self.shortcut = keras.Sequential()# 短接层\n",
    "            self.shortcut.add(keras.layers.Conv2D(filters=filter_num,kernel_size = (1,1),strides = stride))\n",
    "        else:\n",
    "            self.shortcut = lambda x:x\n",
    "        \n",
    "    def call(self,inputs,training = None):\n",
    "        out = self.conv1(inputs)\n",
    "        out = self.bn1(out,training=training)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out,training=training)\n",
    "        downsample = self.shortcut(inputs)\n",
    "        output = keras.layers.add([downsample,out])# 两个tensor相加最好用这种方式\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据上面的基本传递层,构建ResNet的基本单元:block并构建挣个模型\n",
    "# 一个resblock中包含若干个BasicBlock, 一般是2~3个\n",
    "class ResNet(keras.Model):\n",
    "    def __init__(self,layer_dimensions, num_class): \n",
    "        # layer_dimensions参数定义了模型的结构,例如 [2,2,2,2]就表示了模型中又4个resblock,低1,2,3,4个resblock中的粉笔包含2,2,2,2个BasicBlock\n",
    "        # num_class表示输出的分类的数量\n",
    "        super(ResNet,self).__init__()\n",
    "        # 创建网络输入处的预处理卷积层\n",
    "        self.root_preprepare = keras.Sequential([keras.layers.Conv2D(64,(3,3),strides = (1,1), padding = 'SAME'),\n",
    "                                                keras.layers.BatchNormalization(),\n",
    "                                                keras.layers.Activation('relu'),\n",
    "                                                keras.layers.MaxPool2D(pool_size = (2,2),strides = (1,1),padding = 'SAME')\n",
    "                                                ])\n",
    "        self.layer0 = self.build_resblock(filter_num = 64,block_num = layer_dimensions[0])\n",
    "        self.layer1 = self.build_resblock(filter_num = 128,block_num = layer_dimensions[1],stride = 2)\n",
    "        self.layer2 = self.build_resblock(filter_num = 256,block_num = layer_dimensions[2],stride = 2)\n",
    "        self.layer3 = self.build_resblock(filter_num = 512,block_num = layer_dimensions[3],stride = 2)\n",
    "        # 我们这里嘉定是4个resblock\n",
    "        \n",
    "        # 之前的所有的层计算完成之后对于后边的层来说前面计算得到的产物的大小维度是不确定的\n",
    "        # 我们假设之前的计算得到的是[b,512,h,w]\n",
    "        # 对齐进行GlobalPooling处理, 得到的输出是将w,h整个图片进行平均值\n",
    "        # 得到的结果就是[b,512,1]大小的\n",
    "        self.avgpooling = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_class)\n",
    "        \n",
    "        # 这样完成了所有层的定义\n",
    "        \n",
    "     \n",
    "    def call(self,inputs,training = None):\n",
    "        x = self.root_preprepare(inputs,training=training)\n",
    "#         print(x)\n",
    "        x = self.layer0(x,training=training)\n",
    "        x = self.layer1(x,training=training)\n",
    "        x = self.layer2(x,training=training)\n",
    "        x = self.layer3(x,training=training)\n",
    "        \n",
    "        x = self.avgpooling(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        # 我们的分类任务是100类的, 所以输出的大小维度是[b,100]\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def build_resblock(self,filter_num,block_num,stride = 1):\n",
    "        resblocks = keras.Sequential()\n",
    "        resblocks.add(BasicBlock(filter_num,stride)) # 只给第一个传递块下采样的功能, 后续的层全部都设定为不下采样的\n",
    "        for i in range(1,block_num):\n",
    "            resblocks.add(BasicBlock(filter_num,stride = 1)) # 后续的传递块全部都不下采样\n",
    "        return resblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义不同深度以及不同输出大小维度的ResNet的接口\n",
    "def ResNet18():\n",
    "    return ResNet(layer_dimensions = [2,2,2,2], num_class = 100)\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(layer_dimensions = [3,4,6,3], num_class = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), TensorShape([50000]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_train,label_train),(data_test,label_test) = keras.datasets.cifar100.load_data()\n",
    "label_train = tf.squeeze(label_train,axis=1)\n",
    "label_test = tf.squeeze(label_test,axis=1)\n",
    "data_train.shape,label_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255. \n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_db = tf.data.Dataset.from_tensor_slices((data_train,label_train))\n",
    "    train_db = train_db.shuffle(10000).map(preprocess).batch(256)\n",
    "    \n",
    "    test_db = tf.data.Dataset.from_tensor_slices((data_test,label_test))\n",
    "    test_db = test_db.shuffle(10000).map(preprocess).batch(256)\n",
    "    \n",
    "    model = ResNet18()\n",
    "#     model.build(input_shape = (None,32,32,3))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        for step,(x,y) in enumerate(train_db):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x,training=True)\n",
    "                y_onehot = tf.one_hot(y,depth=100)\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot,logits,from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "                \n",
    "            grads = tape.gradient(loss,model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "            if step%100 == 0:\n",
    "                print(epoch,step,'loss: ',loss.numpy())\n",
    "        \n",
    "        total_num = 0\n",
    "        total_correct = 0\n",
    "        for (x,y) in test_db:\n",
    "            logits = model(x)\n",
    "            prob = tf.nn.softmax(logits,axis=1)\n",
    "            pred = tf.argmax(prob,axis=1)\n",
    "            pred = tf.cast(pred,dtype=tf.int32)\n",
    "            \n",
    "            correct = tf.cast(tf.equal(pred,y),dtype=tf.int32)\n",
    "            correct = tf.reduce_sum(correct)\n",
    "            total_correct+= int(correct)\n",
    "            total_num += x.shape[0]\n",
    "        acc = total_correct/total_num\n",
    "        print(epoch,'Accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss:  5.421026\n",
      "0 100 loss:  3.2155776\n",
      "0 Accuracy:  0.0139\n",
      "1 0 loss:  3.039382\n",
      "1 100 loss:  2.644591\n",
      "1 Accuracy:  0.0199\n",
      "2 0 loss:  2.412082\n",
      "2 100 loss:  2.218904\n",
      "2 Accuracy:  0.2274\n",
      "3 0 loss:  1.9199833\n",
      "3 100 loss:  1.6484944\n",
      "3 Accuracy:  0.3383\n",
      "4 0 loss:  1.4039509\n",
      "4 100 loss:  1.1718652\n",
      "4 Accuracy:  0.3467\n",
      "5 0 loss:  0.9372132\n",
      "5 100 loss:  0.6304083\n",
      "5 Accuracy:  0.3373\n",
      "6 0 loss:  0.42826736\n",
      "6 100 loss:  0.18909991\n",
      "6 Accuracy:  0.3653\n",
      "7 0 loss:  0.14116764\n",
      "7 100 loss:  0.07670945\n",
      "7 Accuracy:  0.3813\n",
      "8 0 loss:  0.067004085\n",
      "8 100 loss:  0.036363807\n",
      "8 Accuracy:  0.3897\n",
      "9 0 loss:  0.020149644\n",
      "9 100 loss:  0.030588757\n",
      "9 Accuracy:  0.3868\n",
      "10 0 loss:  0.017170336\n",
      "10 100 loss:  0.013866104\n",
      "10 Accuracy:  0.3853\n",
      "11 0 loss:  0.010362391\n",
      "11 100 loss:  0.01578324\n",
      "11 Accuracy:  0.3888\n",
      "12 0 loss:  0.011500987\n",
      "12 100 loss:  0.02702912\n",
      "12 Accuracy:  0.3738\n",
      "13 0 loss:  0.011322264\n",
      "13 100 loss:  0.006753711\n",
      "13 Accuracy:  0.3125\n",
      "14 0 loss:  0.028831156\n",
      "14 100 loss:  0.2970064\n",
      "14 Accuracy:  0.1873\n",
      "15 0 loss:  0.5612023\n",
      "15 100 loss:  0.25022793\n",
      "15 Accuracy:  0.3052\n",
      "16 0 loss:  0.08342136\n",
      "16 100 loss:  0.045115512\n",
      "16 Accuracy:  0.3896\n",
      "17 0 loss:  0.012681073\n",
      "17 100 loss:  0.0072377617\n",
      "17 Accuracy:  0.4004\n",
      "18 0 loss:  0.0068916567\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-b666be8cac03>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'loss: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m           kwargs={\"name\": name})\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1915\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[0;32m   1923\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1924\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1925\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[1;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[0;32m    483\u001b[0m           update_ops.extend(\n\u001b[0;32m    484\u001b[0m               distribution.extended.update(\n\u001b[1;32m--> 485\u001b[1;33m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2140\u001b[0m     \u001b[1;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   2146\u001b[0m     \u001b[1;31m# once that value is used for something.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m    465\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m\"apply_state\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"apply_state\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[1;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[0;32m    202\u001b[0m           \u001b[0mcoefficients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epsilon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m           use_locking=self._use_locking)\n\u001b[0m\u001b[0;32m    205\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vhat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files (x86)\\python3.6\\lib\\site-packages\\tensorflow_core\\python\\training\\gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[1;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[0;32m   1523\u001b[0m         \u001b[1;34m\"ResourceApplyAdam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m         \u001b[0mbeta1_power\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2_power\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1525\u001b[1;33m         \"use_locking\", use_locking, \"use_nesterov\", use_nesterov)\n\u001b[0m\u001b[0;32m   1526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
