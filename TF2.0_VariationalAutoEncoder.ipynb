{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(imgs,name):\n",
    "    new_img = Image.new('L',(280,280))\n",
    "    index = 0\n",
    "    for i in range(0,280,28):\n",
    "        for j in range(0,280,28):\n",
    "            im = imgs[index]\n",
    "            im = Image.fromarray(im,mode='L')\n",
    "            new_img.paste(im,(i,j))\n",
    "            index += 1\n",
    "            \n",
    "    new_img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数定义\n",
    "h_dim = 20  #最终降维之后的维度\n",
    "batchsz = 512\n",
    "learning_rate = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255.\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data,train_label),(test_data,test_label) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "db = db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices(test_data)\n",
    "test_db = test_db.map(preprocess).batch(batchsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "    def __init__(self,h_dim):  # h_dim是中间隐藏层的维度\n",
    "        super(AE,self).__init__()\n",
    "        # 首先定义编码器\n",
    "        self.encoder = keras.Sequential([\n",
    "            keras.layers.Dense(256,activation = tf.nn.relu,),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(128,activation = tf.nn.relu,),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(h_dim),\n",
    "        ])\n",
    "        \n",
    "        # 定义解码器\n",
    "        self.decoder = keras.Sequential([\n",
    "            keras.layers.Dense(128,activation = tf.nn.relu,),\n",
    "#             keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(256,activation = tf.nn.relu,),\n",
    "#             keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(784),\n",
    "        ])\n",
    "    \n",
    "    def call(self,inputs,training = None):\n",
    "        # 首先编码成隐藏层数据\n",
    "        h = self.encoder(inputs)\n",
    "        \n",
    "        # 接下来进行解码\n",
    "        x_hat = self.decoder(h)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 10 # 降维隐藏层维度(均值/方差层)\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        # Encoder\n",
    "        self.fc1 = keras.layers.Dense(128,activation=tf.nn.relu)\n",
    "        \n",
    "        self.fc2 = keras.layers.Dense(z_dim)  # get mean-value prediction\n",
    "        \n",
    "        self.fc3 = keras.layers.Dense(z_dim)  # get variance prediction\n",
    "        \n",
    "        # Decoder\n",
    "        \n",
    "        self.fc4 = keras.layers.Dense(128,activation=tf.nn.relu)\n",
    "        \n",
    "        self.fc5 = keras.layers.Dense(784)    # 输出大小和输入一样大, 这里没加激活函数\n",
    "        \n",
    "    \n",
    "    def encoder(self,x):\n",
    "        # get mean \n",
    "        mu = self.fc2(self.fc1(x))\n",
    "        \n",
    "        # get variance, 返回的variance是一个log值, 区间是负无穷到正无穷\n",
    "        log_variance = self.fc3(self.fc1(x))\n",
    "        \n",
    "        return mu, log_variance\n",
    "    \n",
    "    def decoder(self,z):\n",
    "        out = self.fc5(self.fc4(z))\n",
    "        return out\n",
    "    \n",
    "    def reparameterization(self,mu,log_variance):\n",
    "        eps = tf.random.normal(log_variance.shape)\n",
    "        \n",
    "        std = tf.exp(log_variance)**0.5\n",
    "        \n",
    "        z = mu + std*eps\n",
    "        return z \n",
    "        \n",
    "    def call(self,inputs,training = None):\n",
    "        # [b,784] ---> [b,z_dim],[b,z_dim]\n",
    "        mu, log_variance = self.encoder(inputs)\n",
    "        \n",
    "        # reparameterization trick\n",
    "        z = self.reparameterization(mu,log_variance)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat,mu, log_variance\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 kl div: 5.8214646e-05 ,rec_loss: 382.6278\n",
      "0 100 kl div: 11.627984 ,rec_loss: 284.6993\n",
      "1 0 kl div: 12.361847 ,rec_loss: 275.10934\n",
      "1 100 kl div: 13.4711 ,rec_loss: 254.60876\n",
      "2 0 kl div: 14.656879 ,rec_loss: 252.26834\n",
      "2 100 kl div: 14.117373 ,rec_loss: 251.70723\n",
      "3 0 kl div: 14.192165 ,rec_loss: 252.00851\n",
      "3 100 kl div: 14.438064 ,rec_loss: 251.0354\n",
      "4 0 kl div: 14.40872 ,rec_loss: 245.00447\n",
      "4 100 kl div: 14.6530485 ,rec_loss: 238.9171\n",
      "5 0 kl div: 14.259886 ,rec_loss: 241.88979\n",
      "5 100 kl div: 14.237668 ,rec_loss: 244.97278\n",
      "6 0 kl div: 14.681679 ,rec_loss: 234.17035\n",
      "6 100 kl div: 14.552263 ,rec_loss: 238.93242\n",
      "7 0 kl div: 14.450032 ,rec_loss: 238.82028\n",
      "7 100 kl div: 15.273353 ,rec_loss: 238.68814\n",
      "8 0 kl div: 14.691032 ,rec_loss: 234.54947\n",
      "8 100 kl div: 14.425978 ,rec_loss: 236.42857\n",
      "9 0 kl div: 14.46881 ,rec_loss: 238.73055\n",
      "9 100 kl div: 14.85593 ,rec_loss: 230.45891\n",
      "10 0 kl div: 14.959202 ,rec_loss: 235.99872\n",
      "10 100 kl div: 15.056475 ,rec_loss: 235.12439\n",
      "11 0 kl div: 14.742031 ,rec_loss: 231.5101\n",
      "11 100 kl div: 14.736872 ,rec_loss: 236.42284\n",
      "12 0 kl div: 14.857845 ,rec_loss: 232.39455\n",
      "12 100 kl div: 14.903447 ,rec_loss: 231.0221\n",
      "13 0 kl div: 15.461896 ,rec_loss: 230.32382\n",
      "13 100 kl div: 14.855949 ,rec_loss: 235.27762\n",
      "14 0 kl div: 14.778823 ,rec_loss: 235.01808\n",
      "14 100 kl div: 15.189087 ,rec_loss: 229.45497\n",
      "15 0 kl div: 15.044221 ,rec_loss: 237.38196\n",
      "15 100 kl div: 14.938808 ,rec_loss: 229.50204\n",
      "16 0 kl div: 14.844388 ,rec_loss: 232.44446\n",
      "16 100 kl div: 15.222071 ,rec_loss: 232.587\n",
      "17 0 kl div: 15.056059 ,rec_loss: 232.4399\n",
      "17 100 kl div: 15.382742 ,rec_loss: 224.78885\n",
      "18 0 kl div: 15.456606 ,rec_loss: 231.37608\n",
      "18 100 kl div: 14.999053 ,rec_loss: 234.97473\n",
      "19 0 kl div: 15.804789 ,rec_loss: 233.90544\n",
      "19 100 kl div: 14.560179 ,rec_loss: 232.04279\n",
      "20 0 kl div: 15.224397 ,rec_loss: 232.8773\n",
      "20 100 kl div: 15.04426 ,rec_loss: 233.49252\n",
      "21 0 kl div: 15.462822 ,rec_loss: 224.33377\n",
      "21 100 kl div: 14.745531 ,rec_loss: 229.66837\n",
      "22 0 kl div: 15.423073 ,rec_loss: 227.15997\n",
      "22 100 kl div: 15.385677 ,rec_loss: 230.7322\n",
      "23 0 kl div: 14.909152 ,rec_loss: 226.2828\n",
      "23 100 kl div: 15.1592045 ,rec_loss: 234.6562\n",
      "24 0 kl div: 15.145451 ,rec_loss: 231.56204\n",
      "24 100 kl div: 15.87292 ,rec_loss: 229.67535\n",
      "25 0 kl div: 15.284847 ,rec_loss: 230.25455\n",
      "25 100 kl div: 14.505234 ,rec_loss: 230.52283\n",
      "26 0 kl div: 14.737176 ,rec_loss: 234.20552\n",
      "26 100 kl div: 15.380898 ,rec_loss: 235.17607\n",
      "27 0 kl div: 14.992926 ,rec_loss: 229.93535\n",
      "27 100 kl div: 15.055512 ,rec_loss: 230.4328\n",
      "28 0 kl div: 15.913872 ,rec_loss: 230.64093\n",
      "28 100 kl div: 14.998989 ,rec_loss: 227.64153\n",
      "29 0 kl div: 14.881755 ,rec_loss: 225.66809\n",
      "29 100 kl div: 15.468798 ,rec_loss: 230.38188\n",
      "30 0 kl div: 14.919107 ,rec_loss: 229.07845\n",
      "30 100 kl div: 14.674413 ,rec_loss: 226.6154\n",
      "31 0 kl div: 15.443788 ,rec_loss: 231.95644\n",
      "31 100 kl div: 15.30986 ,rec_loss: 231.7172\n",
      "32 0 kl div: 15.469987 ,rec_loss: 228.55035\n",
      "32 100 kl div: 15.139562 ,rec_loss: 233.10115\n",
      "33 0 kl div: 14.952616 ,rec_loss: 228.35652\n",
      "33 100 kl div: 15.439795 ,rec_loss: 229.99707\n",
      "34 0 kl div: 15.362777 ,rec_loss: 235.22246\n",
      "34 100 kl div: 15.506259 ,rec_loss: 233.12128\n",
      "35 0 kl div: 15.375615 ,rec_loss: 228.29254\n",
      "35 100 kl div: 15.409069 ,rec_loss: 227.53125\n",
      "36 0 kl div: 14.978683 ,rec_loss: 226.95767\n",
      "36 100 kl div: 15.4502125 ,rec_loss: 232.1386\n",
      "37 0 kl div: 15.050699 ,rec_loss: 226.3596\n",
      "37 100 kl div: 15.025671 ,rec_loss: 224.00034\n",
      "38 0 kl div: 15.585239 ,rec_loss: 228.07115\n",
      "38 100 kl div: 15.182759 ,rec_loss: 232.60022\n",
      "39 0 kl div: 15.3536 ,rec_loss: 225.7154\n",
      "39 100 kl div: 14.865808 ,rec_loss: 232.39075\n",
      "40 0 kl div: 14.9819145 ,rec_loss: 227.69498\n",
      "40 100 kl div: 15.441579 ,rec_loss: 229.4562\n",
      "41 0 kl div: 15.069276 ,rec_loss: 226.06978\n",
      "41 100 kl div: 14.932185 ,rec_loss: 228.86102\n",
      "42 0 kl div: 15.233459 ,rec_loss: 229.24438\n",
      "42 100 kl div: 15.853476 ,rec_loss: 230.91327\n",
      "43 0 kl div: 14.927124 ,rec_loss: 230.38225\n",
      "43 100 kl div: 15.3226185 ,rec_loss: 224.71904\n",
      "44 0 kl div: 14.922054 ,rec_loss: 226.96922\n",
      "44 100 kl div: 15.423434 ,rec_loss: 232.13931\n",
      "45 0 kl div: 14.687048 ,rec_loss: 223.52156\n",
      "45 100 kl div: 15.500249 ,rec_loss: 232.22093\n",
      "46 0 kl div: 15.246313 ,rec_loss: 227.81317\n",
      "46 100 kl div: 15.495208 ,rec_loss: 228.81628\n",
      "47 0 kl div: 15.159952 ,rec_loss: 229.96555\n",
      "47 100 kl div: 15.083195 ,rec_loss: 234.34138\n",
      "48 0 kl div: 14.808271 ,rec_loss: 232.04901\n",
      "48 100 kl div: 14.993291 ,rec_loss: 228.2782\n",
      "49 0 kl div: 15.093857 ,rec_loss: 225.33572\n",
      "49 100 kl div: 15.002116 ,rec_loss: 234.83163\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "for epoch in range(50):\n",
    "    for step,x in enumerate(db):\n",
    "        x = tf.reshape(x,[-1,784])\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_hat_logits,mu,log_variance = model(x)\n",
    "            rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x,logits=x_hat_logits)\n",
    "            rec_loss = tf.reduce_sum(rec_loss)/x.shape[0]\n",
    "            # compute KL divergence (mu,var) ~ N(0,1)\n",
    "            kl_div = -0.5* (log_variance+1-mu**2 - tf.exp(log_variance))\n",
    "            kl_div = tf.reduce_sum(kl_div)/x.shape[0]\n",
    "            loss = rec_loss + 1. * kl_div\n",
    "        grads = tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "        if step % 100 == 0:\n",
    "            print(epoch,step,'kl div:',kl_div.numpy(),',rec_loss:',rec_loss.numpy())\n",
    "    \n",
    "    # evaluation \n",
    "    z = tf.random.normal((batchsz,z_dim))\n",
    "    logits = model.decoder(z)\n",
    "    x_hat = tf.sigmoid(logits)\n",
    "    x_hat = tf.reshape(x_hat,[-1,28,28]).numpy()*255. \n",
    "    x_hat = x_hat.astype(np.uint8)\n",
    "    save_image(x_hat,'vae_images/sampled_epoch_{}.png'.format(epoch))\n",
    "    \n",
    "    x = next(iter(test_db))\n",
    "    x = tf.reshape(x,[-1,784])\n",
    "    x_hat_logits,_,_ = model(x)\n",
    "    x_hat = tf.sigmoid(x_hat_logits)\n",
    "    x_hat = tf.reshape(x_hat,[-1,28,28]).numpy()*255. \n",
    "    x_hat = x_hat.astype(np.uint8)\n",
    "    save_image(x_hat,'vae_images/recon_epoch_{}.png'.format(epoch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
