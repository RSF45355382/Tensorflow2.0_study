{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通用索引方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=66, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([1,5,5,3])\n",
    "a[0][0]\n",
    "# 获得一个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=78, shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][0]\n",
    "# 获得一个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=94, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][0][2]\n",
    "# 获得一个标量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy格式的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.normal([4,28,28,3])\n",
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape\n",
    "# 读取一层索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1,3].shape\n",
    "# 两层索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1,2,3,2].shape\n",
    "# 四层索引, 获得一个标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=120, shape=(18,), dtype=int32, numpy=\n",
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.range(18)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=124, shape=(1,), dtype=int32, numpy=array([17])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1:]\n",
    "# 切片操作和numpy基本一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=128, shape=(2,), dtype=int32, numpy=array([3, 4])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=132, shape=(17,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多维矩阵也可以实现切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.random.normal([3,25,25,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=146, shape=(5, 2), dtype=float32, numpy=\n",
       "array([[ 1.2873585 ,  0.28682515],\n",
       "       [ 1.2462889 , -0.13766177],\n",
       "       [ 0.2551482 , -2.399497  ],\n",
       "       [ 1.0355536 ,  0.88264173],\n",
       "       [ 0.97955227, -1.9931513 ]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,20,20:,2:]\n",
    "# 多维的切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=153, shape=(5, 4), dtype=float32, numpy=\n",
       "array([[ 0.09219573, -2.0436275 ,  2.1420934 ,  1.1256727 ],\n",
       "       [ 1.4276824 , -0.79754376,  0.211269  , -0.40515053],\n",
       "       [-0.46248397,  0.20963521, -0.12933134, -0.1319697 ],\n",
       "       [-0.47681817, -0.2714438 ,  0.16907796,  0.2211754 ],\n",
       "       [ 1.063781  ,  1.4049748 ,  0.57715386,  1.4489008 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,15,20:]\n",
    "# 切片操作一部分矩阵\n",
    "# 最后一维没有写, 相当于取全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=161, shape=(10, 4), dtype=float32, numpy=\n",
       "array([[ 0.82799816,  0.03751003,  0.616271  ,  0.3717033 ],\n",
       "       [-0.17510365,  0.720787  , -1.2335621 ,  0.31483352],\n",
       "       [ 0.56112367,  2.092395  , -1.540277  ,  0.8558799 ],\n",
       "       [ 0.45571506, -0.05418962,  0.5806122 ,  2.5256934 ],\n",
       "       [-0.05601694,  1.8163462 , -1.4260166 ,  0.298168  ],\n",
       "       [ 0.7502643 , -0.32371765,  1.2873585 ,  0.28682515],\n",
       "       [-0.3987965 , -0.14649075,  1.2462889 , -0.13766177],\n",
       "       [ 0.84489596,  0.925131  ,  0.2551482 , -2.399497  ],\n",
       "       [ 0.70748305,  0.46639317,  1.0355536 ,  0.88264173],\n",
       "       [-0.24988315,  1.20537   ,  0.97955227, -1.9931513 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,20,15:,:]\n",
    "# 最后一维写:,相当于取全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,24,24,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 25, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 25, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,24,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,24,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 25, 25])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:,:,:,2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 25, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:,2,:,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 间隔采样切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 13, 13, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 间隔采样切片操作\n",
    "# 采样操作变为了 start:end:step\n",
    "d[:,::2,::2,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([13])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1,2,::2,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 11])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:,1:20:2,0:21:2,3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 冒号实现倒序的功能, 使用负的step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=233, shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tf.range(4)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=229, shape=(4,), dtype=int32, numpy=array([3, 2, 1, 0])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[::-1]\n",
    "# 从末尾进行倒序的间隔为1的采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=237, shape=(2,), dtype=int32, numpy=array([3, 1])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[::-2]\n",
    "# 从末尾进行倒序的间隔为2的采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=241, shape=(2,), dtype=int32, numpy=array([2, 0])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[2::-2]\n",
    "# 从索引2位置开始进行倒序的间隔为2的采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=279, shape=(2,), dtype=int32, numpy=array([3, 1])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[3:0:-2]\n",
    "# 倒序操作的话, 相应的start也是起始:终止这样的格式, 就是说start的值要大于end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...(三个点)符号实现多个连续维度的完整采样的功能\n",
    "系统会自动识别相应的维度\n",
    "这些维度必须是连续的, 只有连续的才能逻辑上推断出哪些是省略的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.random.normal([3,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 6, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[1,...].shape\n",
    "# 这里...相当于上面的后面三维数据全部选择:,:,:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[1,...,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 5, 6])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[...,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selective index\n",
    "### 按照自定义顺序进行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照一定的随意顺序, 按照这个随意顺序进行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.ones([3,25,8],dtype = tf.float32)\n",
    "# 3个维度分别是 班级,学生数量, 科目\n",
    "# 想在要对这些数据进行打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 25, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(data,axis=0,indices=[0,2]).shape \n",
    "# axis = 0代表只去第一个维度的,indices代表要取的索引\n",
    "# 按照班级维度进行采样\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这里即使数组索引超限也不会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 25, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(data,axis=0,indices=[2,0,1]).shape \n",
    "# 按照班级维度进行采样\n",
    "# 实现了非顺序采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 7, 8])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(data,axis=1,indices=[2,0,1,17, 9, 8, 3]).shape \n",
    "# 按照学生维度进行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 25, 5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(data,axis=2,indices=[2,0,1,7,3]).shape\n",
    "# 按照科目维度进行采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 另一种采样方法\n",
    "适应于各种采样, 定制化采样\n",
    "tf.gather_nd(data,[]), 这个[]作为最外层的维度锁定, 具体怎么采样看这个方括号内是怎么组合的\n",
    "方括号内的组合方式必须是同一纬度的,例如: [[1,2],[2,3]] 或者[[2,3,2],[2,3,1]] 或者 [2,3]\\\n",
    "\n",
    "下面这种是错误的:\n",
    "[[1,2],[2,3,2]]或者[2,[3,2]]\n",
    "\n",
    "\n",
    "注意:\n",
    "[[[2,3,2],[2,3,1]]]\n",
    "和\n",
    "[[2,3,2],[2,3,1]]\n",
    "这两种都可以实现, 但是他们的shape是不同的, 分别是TensorShape([1,2])和TensorShape([2])\n",
    "#### 一般建议使用两层[],这样最终得到的都是至少是个矩阵, 而不是向量或者标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25, 8])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(data,[0]).shape # 这里在第一个维度上取了0 ,相当于取了第一个班级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(data,[0,1]).shape \n",
    "# 这里在第一个维度上取了0 ,在第二个维度上取了1,相当于取了第一个班级的第二个学生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(data, [0,1,2]).shape \n",
    "# 这里在第一个维度上取了0 ,在第二个维度上取了1,, 第三个维度上取了2, \n",
    "# 相当于取了第一个班级的第二个学生的第三门成绩\n",
    "# 也就是一个标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(data, [[0,1,2]]).shape \n",
    "# 这里在第一个维度上取了0 ,在第二个维度上取了1,, 第三个维度上取了2, \n",
    "# 但是嵌套了2层方括号\n",
    "# 相当于取了第一个班级的第二个学生的第三门成绩\n",
    "# 也就是一个标量的数组, 也就是一个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(data, [[0,1,2],[1,3,2]]).shape \n",
    "# 这里在第一个维度上取了0 ,在第二个维度上取了1,, 第三个维度上取了2, \n",
    "# 这里在第一个维度上取了1 ,在第二个维度上取了3,, 第三个维度上取了2, \n",
    "# 相当于取了第一个班级的第二个学生的第三门成绩\n",
    "# 和第二个班级的第四个学生的第三门成绩\n",
    "# 组成了一个向量\n",
    "# 也就是一个标量的数组, 也就是一个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather_nd(data, [[0,1],[1,3]]).shape \n",
    "# 这里在第一个维度上取了0 ,在第二个维度上取了1,\n",
    "# 这里在第一个维度上取了1 ,在第二个维度上取了3, \n",
    "# 相当于取了第一个班级的第二个学生的所有成绩 - 长度为8\n",
    "# 和第二个班级的第四个学生的所有成绩 - 长度为8\n",
    "# 组成了一个tensor\n",
    "# 也就是一个标量的数组, 也就是一个矩阵(l两个长度为8的tensor组成一个2*8的tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据true或者false进行索引的切片操作\n",
    "tf.boolean_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 28, 28, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4mask = tf.ones([4,28,28,3])\n",
    "\n",
    "\n",
    "tf.boolean_mask(data_4mask,mask=[True,True,False,False]).shape \n",
    "# 这里True和False代表获取或者跳过\n",
    "# [True,True,False,False] 就相当于获取 0和1索引的, 跳过2和3索引的,\n",
    "# 这里没有设置axis,而且只有一层[]说明是在\n",
    "# 最外层的索引进行的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 28, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.boolean_mask(data_4mask,mask=[True,True,False],axis=3).shape \n",
    "# 这里相当于是一个在axis = 3的维度上取了index为0和1的所有数据, 而跳过了index是2的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 4])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4mask_bool = tf.ones([2,3,4])\n",
    "\n",
    "tf.boolean_mask(data_4mask_bool,mask=[[True, True, False],[False, False,True]]).shape\n",
    "\n",
    "# 这里mask参数传入的是两层的[],说明代表的是两维的数据, 也就是说[2,3,4]维度中对应了[2,3]\n",
    "# 所以,如上边, 我们传入的True/False的数组也是一个2*3的大小的数据\n",
    "# 取出来的, 第一部分[True, True, False]是在data_4mask_bool[0]这个3*4大小的矩阵中\n",
    "# 获取第一行和第二行,跳过第三行\n",
    "# 第一部分[False, False,True]是在data_4mask_bool[1]这个3*4大小的矩阵中\n",
    "# 获取第三行, 跳过第一行和第二行\n",
    "# 所以最终得到的是一个3*4大小的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
