{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "tf.random.set_seed(2345)\n",
    "\n",
    "# 因为默认tf会吧全部显存都占用光, 所以在进行卷积计算的时候回报错提示无法初始化cuDNN, 所以这里我们需要手动的将tf设置成按需占用内存\n",
    "# 这样就避免了卷积计算错误的问题\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train,label_train),(data_test,label_test) = keras.datasets.cifar100.load_data()\n",
    "label_train = tf.squeeze(label_train,axis=1)\n",
    "label_test = tf.squeeze(label_test,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), TensorShape([50000]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape,label_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义五个卷积单元, 我们使用每个卷积单元是2个卷积层串联加一个maxpooling层\n",
    "conv_layers = [\n",
    "    # unit 1\n",
    "    keras.layers.Conv2D(64,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),# 卷积层也可以使用激活函数\n",
    "    keras.layers.Conv2D(64,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='SAME'),\n",
    "    \n",
    "    # unit 2\n",
    "    keras.layers.Conv2D(128,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),# 卷积层也可以使用激活函数\n",
    "    keras.layers.Conv2D(128,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='SAME'),\n",
    "    \n",
    "    # unit 3\n",
    "    keras.layers.Conv2D(256,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),# 卷积层也可以使用激活函数\n",
    "    keras.layers.Conv2D(256,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='SAME'),\n",
    "    \n",
    "    # unit 4\n",
    "    keras.layers.Conv2D(512,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),# 卷积层也可以使用激活函数\n",
    "    keras.layers.Conv2D(512,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='SAME'),\n",
    "    \n",
    "    # unit 5\n",
    "    keras.layers.Conv2D(512,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),# 卷积层也可以使用激活函数\n",
    "    keras.layers.Conv2D(512,kernel_size=[3,3],strides=1,padding='SAME',activation=tf.nn.relu),\n",
    "    keras.layers.MaxPool2D(pool_size=[2,2],strides=2,padding='SAME'),\n",
    "]\n",
    "# 这样就得到了一个10层的卷积神经网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255. \n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_db = tf.data.Dataset.from_tensor_slices((data_train,label_train))\n",
    "    train_db = train_db.shuffle(10000).map(preprocess).batch(256)\n",
    "    \n",
    "    test_db = tf.data.Dataset.from_tensor_slices((data_test,label_test))\n",
    "    test_db = test_db.shuffle(10000).map(preprocess).batch(256)\n",
    "    \n",
    "    conv_net = keras.Sequential(conv_layers)\n",
    "    \n",
    "#     x = tf.random.normal([4,32,32,3])\n",
    "#     print(conv_net(x).shape)\n",
    "    fc_net = keras.Sequential([\n",
    "        keras.layers.Dense(256,activation=tf.nn.relu),\n",
    "        keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "        keras.layers.Dense(100,activation=tf.nn.relu)\n",
    "    ])\n",
    "    conv_net.build(input_shape=[None,32,32,3])\n",
    "    fc_net.build(input_shape=[None,512]) \n",
    "    variables =conv_net.trainable_variables + fc_net.trainable_variables\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        for step,(x,y) in enumerate(train_db):\n",
    "            with tf.GradientTape() as tape:\n",
    "                out = conv_net(x)\n",
    "                # [b,32,32,3]转变为了[b,1,1,512]的矩阵\n",
    "                out = tf.reshape(out,[-1,512])\n",
    "                \n",
    "                # 再传入到全连接层中\n",
    "                # [b,512]转变为了[b,100]\n",
    "                logits = fc_net(out)\n",
    "                y_onehot = tf.one_hot(y,depth=100)\n",
    "                loss = tf.losses.categorical_crossentropy(y_onehot,logits,from_logits=True)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "                \n",
    "            grads = tape.gradient(loss,variables)\n",
    "            optimizer.apply_gradients(zip(grads,variables))\n",
    "            if step%100 == 0:\n",
    "                print(epoch,step,'loss: ',loss.numpy())\n",
    "        \n",
    "        total_num = 0\n",
    "        total_correct = 0\n",
    "        for (x,y) in test_db:\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out,[-1,512])\n",
    "            logits = fc_net(out)\n",
    "            prob = tf.nn.softmax(logits,axis=1)\n",
    "            pred = tf.argmax(prob,axis=1)\n",
    "            pred = tf.cast(pred,dtype=tf.int32)\n",
    "            \n",
    "            correct = tf.cast(tf.equal(pred,y),dtype=tf.int32)\n",
    "            correct = tf.reduce_sum(correct)\n",
    "            total_correct+= int(correct)\n",
    "            total_num += x.shape[0]\n",
    "        acc = total_correct/total_num\n",
    "        print(epoch,'Accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss:  5.5419426\n",
      "0 100 loss:  4.174409\n",
      "0 Accuracy:  0.1328\n",
      "1 0 loss:  4.000986\n",
      "1 100 loss:  3.991229\n",
      "1 Accuracy:  0.1728\n",
      "2 0 loss:  3.9446347\n",
      "2 100 loss:  3.71436\n",
      "2 Accuracy:  0.1886\n",
      "3 0 loss:  3.7404895\n",
      "3 100 loss:  3.7387748\n",
      "3 Accuracy:  0.2101\n",
      "4 0 loss:  3.5604115\n",
      "4 100 loss:  3.4384232\n",
      "4 Accuracy:  0.2174\n",
      "5 0 loss:  3.540745\n",
      "5 100 loss:  3.3633566\n",
      "5 Accuracy:  0.2353\n",
      "6 0 loss:  3.3984401\n",
      "6 100 loss:  3.422825\n",
      "6 Accuracy:  0.2529\n",
      "7 0 loss:  3.2521577\n",
      "7 100 loss:  3.2374184\n",
      "7 Accuracy:  0.2631\n",
      "8 0 loss:  3.365357\n",
      "8 100 loss:  3.1660628\n",
      "8 Accuracy:  0.2824\n",
      "9 0 loss:  3.0835934\n",
      "9 100 loss:  3.0234213\n",
      "9 Accuracy:  0.2893\n",
      "10 0 loss:  3.1217113\n",
      "10 100 loss:  3.045132\n",
      "10 Accuracy:  0.2942\n",
      "11 0 loss:  3.189695\n",
      "11 100 loss:  2.9459574\n",
      "11 Accuracy:  0.2991\n",
      "12 0 loss:  2.6475303\n",
      "12 100 loss:  2.7945535\n",
      "12 Accuracy:  0.314\n",
      "13 0 loss:  3.0108073\n",
      "13 100 loss:  2.930768\n",
      "13 Accuracy:  0.3218\n",
      "14 0 loss:  2.8861532\n",
      "14 100 loss:  2.6064332\n",
      "14 Accuracy:  0.3222\n",
      "15 0 loss:  2.730177\n",
      "15 100 loss:  2.7820098\n",
      "15 Accuracy:  0.3355\n",
      "16 0 loss:  2.6648774\n",
      "16 100 loss:  2.5277407\n",
      "16 Accuracy:  0.3397\n",
      "17 0 loss:  2.6705782\n",
      "17 100 loss:  2.6215923\n",
      "17 Accuracy:  0.3409\n",
      "18 0 loss:  2.5556526\n",
      "18 100 loss:  2.5895455\n",
      "18 Accuracy:  0.3391\n",
      "19 0 loss:  2.667454\n",
      "19 100 loss:  2.4608207\n",
      "19 Accuracy:  0.3514\n",
      "20 0 loss:  2.548053\n",
      "20 100 loss:  2.2324462\n",
      "20 Accuracy:  0.3548\n",
      "21 0 loss:  2.590826\n",
      "21 100 loss:  2.2286553\n",
      "21 Accuracy:  0.3508\n",
      "22 0 loss:  2.1984932\n",
      "22 100 loss:  2.1830282\n",
      "22 Accuracy:  0.3537\n",
      "23 0 loss:  2.350944\n",
      "23 100 loss:  2.1063206\n",
      "23 Accuracy:  0.3524\n",
      "24 0 loss:  2.3462102\n",
      "24 100 loss:  2.1378317\n",
      "24 Accuracy:  0.3538\n",
      "25 0 loss:  2.4413517\n",
      "25 100 loss:  1.7077127\n",
      "25 Accuracy:  0.3645\n",
      "26 0 loss:  1.935718\n",
      "26 100 loss:  1.8229235\n",
      "26 Accuracy:  0.3538\n",
      "27 0 loss:  1.966698\n",
      "27 100 loss:  2.0043309\n",
      "27 Accuracy:  0.3553\n",
      "28 0 loss:  1.9943522\n",
      "28 100 loss:  2.0212939\n",
      "28 Accuracy:  0.3467\n",
      "29 0 loss:  2.1972547\n",
      "29 100 loss:  1.8339849\n",
      "29 Accuracy:  0.3505\n",
      "30 0 loss:  1.8885938\n",
      "30 100 loss:  1.4636569\n",
      "30 Accuracy:  0.3474\n",
      "31 0 loss:  1.7748468\n",
      "31 100 loss:  1.564807\n",
      "31 Accuracy:  0.3501\n",
      "32 0 loss:  1.532953\n",
      "32 100 loss:  1.5358739\n",
      "32 Accuracy:  0.3525\n",
      "33 0 loss:  1.4673871\n",
      "33 100 loss:  1.5026284\n",
      "33 Accuracy:  0.3508\n",
      "34 0 loss:  1.5011888\n",
      "34 100 loss:  1.4289087\n",
      "34 Accuracy:  0.3487\n",
      "35 0 loss:  1.3669413\n",
      "35 100 loss:  1.3000952\n",
      "35 Accuracy:  0.3508\n",
      "36 0 loss:  1.3279827\n",
      "36 100 loss:  1.3269906\n",
      "36 Accuracy:  0.3492\n",
      "37 0 loss:  1.3197323\n",
      "37 100 loss:  1.248741\n",
      "37 Accuracy:  0.3471\n",
      "38 0 loss:  1.1522424\n",
      "38 100 loss:  1.4951795\n",
      "38 Accuracy:  0.3476\n",
      "39 0 loss:  1.1115264\n",
      "39 100 loss:  1.4587095\n",
      "39 Accuracy:  0.3421\n",
      "40 0 loss:  1.3736279\n",
      "40 100 loss:  1.1833924\n",
      "40 Accuracy:  0.3422\n",
      "41 0 loss:  1.2908927\n",
      "41 100 loss:  1.4057432\n",
      "41 Accuracy:  0.3467\n",
      "42 0 loss:  1.1425575\n",
      "42 100 loss:  1.3946728\n",
      "42 Accuracy:  0.3409\n",
      "43 0 loss:  1.3457015\n",
      "43 100 loss:  1.2985624\n",
      "43 Accuracy:  0.3471\n",
      "44 0 loss:  0.96189797\n",
      "44 100 loss:  1.0901664\n",
      "44 Accuracy:  0.3441\n",
      "45 0 loss:  1.2530121\n",
      "45 100 loss:  1.1687443\n",
      "45 Accuracy:  0.3441\n",
      "46 0 loss:  1.319764\n",
      "46 100 loss:  1.0662887\n",
      "46 Accuracy:  0.3482\n",
      "47 0 loss:  1.3692356\n",
      "47 100 loss:  1.1573483\n",
      "47 Accuracy:  0.3378\n",
      "48 0 loss:  1.3785537\n",
      "48 100 loss:  1.358027\n",
      "48 Accuracy:  0.3396\n",
      "49 0 loss:  1.4615973\n",
      "49 100 loss:  1.4880495\n",
      "49 Accuracy:  0.3309\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
