{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers,models,Sequential\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_num = 10000\n",
    "max_review_length = 80  # 句子长度限制为80,少的补齐, 多的截取\n",
    "(data_train,label_train),(data_test,label_test) = keras.datasets.imdb.load_data(num_words=max_word_num) \n",
    "# 设定最多编码成10000个单词, 其他出现频率小的单词用位置的一个单词处理\n",
    "# 对句子进行一个padding操作, 农场同样长度为80的句子\n",
    "data_train = keras.preprocessing.sequence.pad_sequences(data_train,maxlen=max_review_length)\n",
    "data_test = keras.preprocessing.sequence.pad_sequences(data_test,maxlen=max_review_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 80), (25000,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape,label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 80), (25000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape,label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train = tf.data.Dataset.from_tensor_slices((data_train,label_train))   \n",
    "# 这里使用from_tensor_slices函数的时候记得一定要输入一个tuple,而不是list, 否则会报错\n",
    "db_test = tf.data.Dataset.from_tensor_slices((data_test,label_test))\n",
    "\n",
    "db_train = db_train.shuffle(1000).batch(512,drop_remainder = True) \n",
    "# 这里,drop_remainder = True 表示如果迭代到最后一个batch, 所剩余的数据不够一个batch大小的时候, 直接舍弃最后一个batch\n",
    "db_test = db_test.batch(512,drop_remainder = True)\n",
    "\n",
    "batchsz = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(label_train),tf.reduce_min(label__test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一个RNN网络模型类\n",
    "class MyRNN(models.Model):\n",
    "    def __init__(self,units,batchsz):\n",
    "        super(MyRNN,self).__init__(self)\n",
    "        embedding_length = 100\n",
    "        max_word_num = 10000\n",
    "        # 将输入数据转换成embedding形式的数据\n",
    "        self.embedding = layers.Embedding(max_word_num,embedding_length, input_length = max_review_length)\n",
    "        # input_length 是句子长度\n",
    "        # embedding_length 是emdding之后的feature长度\n",
    "        # max_word_num是最多编码的单词数量\n",
    "        self.state0 = [tf.zeros([batchsz,units])]\n",
    "        self.state1 = [tf.zeros([batchsz,units])]\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units,dropout = 0.5)\n",
    "        # 这里我们只定义一层的RNN层\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units,dropout = 0.5)\n",
    "        \n",
    "        \n",
    "        self.fc = layers.Dense(1) # 单输出节点完成分类问题\n",
    "        \n",
    "        \n",
    "    def call(self,inputs,training = None):  # training 不是指的时候取默认None代表的是训练模式,这个是约定俗成的规则\n",
    "        x = inputs\n",
    "        # 此时x的大小是[b,80],80是句子长度\n",
    "        \n",
    "        x = self.embedding(x)  # 进行embeding编码\n",
    "        # 编码之后x的格式是[b,80,100], 我们设置的embeding的feature长度是100\n",
    "        \n",
    "        state0 = self.state0\n",
    "        state1 = self.state1\n",
    "        for words in tf.unstack(x,axis=1):# 在1维度上对这个数据进行展开\n",
    "            # 获取了一个batch中的每一句话中的相同位置上的词以后\n",
    "            out0,state0 = self.rnn_cell0(words,state0)\n",
    "            out1,state1 = self.rnn_cell1(out0,state1)\n",
    "            \n",
    "        \n",
    "        # 经过全连接层处理\n",
    "        x = self.fc(out1)\n",
    "        \n",
    "        #计算sigmoid操作\n",
    "        prob = tf.sigmoid(x)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双层RNN模型\n",
    "def main():\n",
    "    units = 64\n",
    "    epochs = 4\n",
    "    batchsz = 512\n",
    "    \n",
    "    model = MyRNN(units,batchsz)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "                 loss = tf.losses.BinaryCrossentropy(),\n",
    "                 metrics = ['accuracy'],\n",
    "                experimental_run_tf_function=False)  # 不加这一句会有不兼容的情况, 会报错\n",
    "    model.fit(db_train,epochs=epochs,validation_data=db_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "48/48 [==============================] - 15s 312ms/step - loss: 0.6800 - accuracy: 0.5123 - val_loss: 0.5299 - val_accuracy: 0.7395\n",
      "Epoch 2/4\n",
      "48/48 [==============================] - 8s 162ms/step - loss: 0.4453 - accuracy: 0.7657 - val_loss: 0.3824 - val_accuracy: 0.8323\n",
      "Epoch 3/4\n",
      "48/48 [==============================] - 8s 162ms/step - loss: 0.3340 - accuracy: 0.8510 - val_loss: 0.4064 - val_accuracy: 0.8322\n",
      "Epoch 4/4\n",
      "48/48 [==============================] - 8s 162ms/step - loss: 0.2782 - accuracy: 0.8864 - val_loss: 0.4474 - val_accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
