{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets,optimizers\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (60000, 28, 28), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x,train_label),(test_x,test_label) = datasets.mnist.load_data()\n",
    "train_label.shape, train_x.shape,test_x.shape,test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]), TensorShape([60000]), tf.float32, tf.int32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为tensor\n",
    "x = tf.convert_to_tensor(train_x,dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(train_label,dtype = tf.int32)\n",
    "x_test = tf.convert_to_tensor(test_x,dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(test_label,dtype = tf.int32)\n",
    "x.shape, y.shape, x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(255.0, shape=(), dtype=float32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(255.0, shape=(), dtype=float32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 查看最小值和最大值\n",
    "print(tf.reduce_min(x))\n",
    "print(tf.reduce_max(x))\n",
    "\n",
    "print(tf.reduce_max(y))\n",
    "print(tf.reduce_min(y))\n",
    "\n",
    "print(tf.reduce_min(x_test))\n",
    "print(tf.reduce_max(x_test))\n",
    "\n",
    "print(tf.reduce_max(y_test))\n",
    "print(tf.reduce_min(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=9814989, shape=(128, 28, 28), dtype=float32, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>, <tf.Tensor: id=9814990, shape=(128,), dtype=int32, numpy=\n",
      "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6,\n",
      "       6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2,\n",
      "       3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4,\n",
      "       6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3,\n",
      "       6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4,\n",
      "       8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5])>) <tensorflow.python.data.ops.iterator_ops.IteratorV2 object at 0x000001A726E6F128>\n"
     ]
    }
   ],
   "source": [
    "# 创建一个数据集对象(实质是一个迭代器/生成器), 可以按照batch来取数据\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(128)\n",
    "# 转换为迭代器之后,获取下一个batch\n",
    "train_iter = iter(train_db)\n",
    "sample_train = train_iter.next()\n",
    "# 获得的sample是一个元组(x,y)的格式\n",
    "sample[0].shape, sample[1].shape\n",
    "test_iter = iter(test_db)\n",
    "sample_test = test_iter.next()\n",
    "print(sample_test,train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是[b,784] => [b,512] = > [b,256] => [b,10]\n",
    "# 转化为tf.Vatiable的目的是为了让tf.GradientTaps()能够跟踪\n",
    "# tf.GradientTaps()只能跟踪tfVariable的对象的梯度\n",
    "# 方差设定为0.1, 有助于网络收敛\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784,512],stddev = 0.01))\n",
    "b1 = tf.Variable(tf.ones([512]))\n",
    "\n",
    "w2 = tf.Variable(tf.random.truncated_normal([512,256],stddev = 0.01))\n",
    "b2 = tf.Variable(tf.ones([256]))\n",
    "\n",
    "w3 = tf.Variable(tf.random.truncated_normal([256,10],stddev = 0.01))\n",
    "b3 = tf.Variable(tf.ones([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Step: 0  ,Loss: tf.Tensor(0.92763245, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 100  ,Loss: tf.Tensor(0.8377632, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 200  ,Loss: tf.Tensor(0.75881994, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 300  ,Loss: tf.Tensor(0.690096, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 400  ,Loss: tf.Tensor(0.6208563, shape=(), dtype=float32)\n",
      "Epoch: 0 ,Accuracy: 0.0974\n",
      "Epoch: 1  Step: 0  ,Loss: tf.Tensor(0.5860266, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 100  ,Loss: tf.Tensor(0.5323427, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 200  ,Loss: tf.Tensor(0.48528847, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 300  ,Loss: tf.Tensor(0.44467035, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 400  ,Loss: tf.Tensor(0.4024671, shape=(), dtype=float32)\n",
      "Epoch: 1 ,Accuracy: 0.0974\n",
      "Epoch: 2  Step: 0  ,Loss: tf.Tensor(0.38253266, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 100  ,Loss: tf.Tensor(0.35040325, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 200  ,Loss: tf.Tensor(0.32235777, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 300  ,Loss: tf.Tensor(0.29843026, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 400  ,Loss: tf.Tensor(0.27265817, shape=(), dtype=float32)\n",
      "Epoch: 2 ,Accuracy: 0.0974\n",
      "Epoch: 3  Step: 0  ,Loss: tf.Tensor(0.26144105, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 100  ,Loss: tf.Tensor(0.2423058, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 200  ,Loss: tf.Tensor(0.22567931, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 300  ,Loss: tf.Tensor(0.21168943, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 400  ,Loss: tf.Tensor(0.19596176, shape=(), dtype=float32)\n",
      "Epoch: 3 ,Accuracy: 0.0974\n",
      "Epoch: 4  Step: 0  ,Loss: tf.Tensor(0.1898055, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 100  ,Loss: tf.Tensor(0.17850208, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 200  ,Loss: tf.Tensor(0.16871578, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 300  ,Loss: tf.Tensor(0.16060074, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 400  ,Loss: tf.Tensor(0.15101108, shape=(), dtype=float32)\n",
      "Epoch: 4 ,Accuracy: 0.0974\n",
      "Epoch: 5  Step: 0  ,Loss: tf.Tensor(0.14773835, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 100  ,Loss: tf.Tensor(0.14112993, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 200  ,Loss: tf.Tensor(0.1354104, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 300  ,Loss: tf.Tensor(0.1307269, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 400  ,Loss: tf.Tensor(0.12488266, shape=(), dtype=float32)\n",
      "Epoch: 5 ,Accuracy: 0.0974\n",
      "Epoch: 6  Step: 0  ,Loss: tf.Tensor(0.12320963, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 100  ,Loss: tf.Tensor(0.11939784, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 200  ,Loss: tf.Tensor(0.11607633, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 300  ,Loss: tf.Tensor(0.113369465, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 400  ,Loss: tf.Tensor(0.10981128, shape=(), dtype=float32)\n",
      "Epoch: 6 ,Accuracy: 0.0974\n",
      "Epoch: 7  Step: 0  ,Loss: tf.Tensor(0.10899395, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 100  ,Loss: tf.Tensor(0.10683914, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 200  ,Loss: tf.Tensor(0.10492085, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 300  ,Loss: tf.Tensor(0.10333513, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 400  ,Loss: tf.Tensor(0.10117694, shape=(), dtype=float32)\n",
      "Epoch: 7 ,Accuracy: 0.0973\n",
      "Epoch: 8  Step: 0  ,Loss: tf.Tensor(0.100793764, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 100  ,Loss: tf.Tensor(0.099617526, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 200  ,Loss: tf.Tensor(0.09851549, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 300  ,Loss: tf.Tensor(0.097554885, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 400  ,Loss: tf.Tensor(0.09626006, shape=(), dtype=float32)\n",
      "Epoch: 8 ,Accuracy: 0.0973\n",
      "Epoch: 9  Step: 0  ,Loss: tf.Tensor(0.09607881, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 100  ,Loss: tf.Tensor(0.095480084, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 200  ,Loss: tf.Tensor(0.094850816, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 300  ,Loss: tf.Tensor(0.09423173, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 400  ,Loss: tf.Tensor(0.09347521, shape=(), dtype=float32)\n",
      "Epoch: 9 ,Accuracy: 0.0975\n",
      "Epoch: 10  Step: 0  ,Loss: tf.Tensor(0.0933724, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 100  ,Loss: tf.Tensor(0.09311532, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 200  ,Loss: tf.Tensor(0.09275931, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 300  ,Loss: tf.Tensor(0.09232204, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 400  ,Loss: tf.Tensor(0.09190598, shape=(), dtype=float32)\n",
      "Epoch: 10 ,Accuracy: 0.1084\n",
      "Epoch: 11  Step: 0  ,Loss: tf.Tensor(0.091819316, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 100  ,Loss: tf.Tensor(0.09176541, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 200  ,Loss: tf.Tensor(0.09156731, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 300  ,Loss: tf.Tensor(0.09122327, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 400  ,Loss: tf.Tensor(0.09102626, shape=(), dtype=float32)\n",
      "Epoch: 11 ,Accuracy: 0.1136\n",
      "Epoch: 12  Step: 0  ,Loss: tf.Tensor(0.09092684, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 100  ,Loss: tf.Tensor(0.09099479, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 200  ,Loss: tf.Tensor(0.09088817, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 300  ,Loss: tf.Tensor(0.09058922, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 400  ,Loss: tf.Tensor(0.090535864, shape=(), dtype=float32)\n",
      "Epoch: 12 ,Accuracy: 0.1007\n",
      "Epoch: 13  Step: 0  ,Loss: tf.Tensor(0.09041244, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 100  ,Loss: tf.Tensor(0.09055434, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 200  ,Loss: tf.Tensor(0.090500936, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 300  ,Loss: tf.Tensor(0.09022154, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 400  ,Loss: tf.Tensor(0.0902643, shape=(), dtype=float32)\n",
      "Epoch: 13 ,Accuracy: 0.1081\n",
      "Epoch: 14  Step: 0  ,Loss: tf.Tensor(0.09011449, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 100  ,Loss: tf.Tensor(0.090301886, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 200  ,Loss: tf.Tensor(0.09027969, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 300  ,Loss: tf.Tensor(0.09000678, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 400  ,Loss: tf.Tensor(0.09011515, shape=(), dtype=float32)\n",
      "Epoch: 14 ,Accuracy: 0.136\n",
      "Epoch: 15  Step: 0  ,Loss: tf.Tensor(0.08994066, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 100  ,Loss: tf.Tensor(0.090156585, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 200  ,Loss: tf.Tensor(0.09015287, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 300  ,Loss: tf.Tensor(0.08988012, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 400  ,Loss: tf.Tensor(0.090034105, shape=(), dtype=float32)\n",
      "Epoch: 15 ,Accuracy: 0.1259\n",
      "Epoch: 16  Step: 0  ,Loss: tf.Tensor(0.08983827, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 100  ,Loss: tf.Tensor(0.09007241, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 200  ,Loss: tf.Tensor(0.09007979, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 300  ,Loss: tf.Tensor(0.089804545, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 400  ,Loss: tf.Tensor(0.08999073, shape=(), dtype=float32)\n",
      "Epoch: 16 ,Accuracy: 0.1184\n",
      "Epoch: 17  Step: 0  ,Loss: tf.Tensor(0.08977721, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 100  ,Loss: tf.Tensor(0.090023234, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 200  ,Loss: tf.Tensor(0.090037376, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 300  ,Loss: tf.Tensor(0.08975868, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 400  ,Loss: tf.Tensor(0.08996798, shape=(), dtype=float32)\n",
      "Epoch: 17 ,Accuracy: 0.1157\n",
      "Epoch: 18  Step: 0  ,Loss: tf.Tensor(0.089740194, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 100  ,Loss: tf.Tensor(0.08999415, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 200  ,Loss: tf.Tensor(0.09001249, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 300  ,Loss: tf.Tensor(0.0897303, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 400  ,Loss: tf.Tensor(0.08995644, shape=(), dtype=float32)\n",
      "Epoch: 18 ,Accuracy: 0.1147\n",
      "Epoch: 19  Step: 0  ,Loss: tf.Tensor(0.089717284, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 100  ,Loss: tf.Tensor(0.089976646, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 200  ,Loss: tf.Tensor(0.089997664, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 300  ,Loss: tf.Tensor(0.08971238, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 400  ,Loss: tf.Tensor(0.08995086, shape=(), dtype=float32)\n",
      "Epoch: 19 ,Accuracy: 0.114\n",
      "Epoch: 20  Step: 0  ,Loss: tf.Tensor(0.08970279, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 100  ,Loss: tf.Tensor(0.089965925, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20  Step: 200  ,Loss: tf.Tensor(0.08998867, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 300  ,Loss: tf.Tensor(0.08970077, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 400  ,Loss: tf.Tensor(0.089948356, shape=(), dtype=float32)\n",
      "Epoch: 20 ,Accuracy: 0.1136\n",
      "Epoch: 21  Step: 0  ,Loss: tf.Tensor(0.08969339, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 100  ,Loss: tf.Tensor(0.08995919, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 200  ,Loss: tf.Tensor(0.08998306, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 300  ,Loss: tf.Tensor(0.08969303, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 400  ,Loss: tf.Tensor(0.08994738, shape=(), dtype=float32)\n",
      "Epoch: 21 ,Accuracy: 0.1136\n",
      "Epoch: 22  Step: 0  ,Loss: tf.Tensor(0.08968712, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 100  ,Loss: tf.Tensor(0.08995483, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 200  ,Loss: tf.Tensor(0.089979455, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 300  ,Loss: tf.Tensor(0.089687705, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 400  ,Loss: tf.Tensor(0.08994712, shape=(), dtype=float32)\n",
      "Epoch: 22 ,Accuracy: 0.1136\n",
      "Epoch: 23  Step: 0  ,Loss: tf.Tensor(0.08968277, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 100  ,Loss: tf.Tensor(0.08995187, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 200  ,Loss: tf.Tensor(0.08997701, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 300  ,Loss: tf.Tensor(0.089683935, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 400  ,Loss: tf.Tensor(0.08994714, shape=(), dtype=float32)\n",
      "Epoch: 23 ,Accuracy: 0.1136\n",
      "Epoch: 24  Step: 0  ,Loss: tf.Tensor(0.08967967, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 100  ,Loss: tf.Tensor(0.08994978, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 200  ,Loss: tf.Tensor(0.08997528, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 300  ,Loss: tf.Tensor(0.089681186, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 400  ,Loss: tf.Tensor(0.089947246, shape=(), dtype=float32)\n",
      "Epoch: 24 ,Accuracy: 0.1136\n",
      "Epoch: 25  Step: 0  ,Loss: tf.Tensor(0.08967738, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 100  ,Loss: tf.Tensor(0.08994826, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 200  ,Loss: tf.Tensor(0.08997401, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 300  ,Loss: tf.Tensor(0.089679115, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 400  ,Loss: tf.Tensor(0.08994734, shape=(), dtype=float32)\n",
      "Epoch: 25 ,Accuracy: 0.1136\n",
      "Epoch: 26  Step: 0  ,Loss: tf.Tensor(0.08967562, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 100  ,Loss: tf.Tensor(0.089947075, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 200  ,Loss: tf.Tensor(0.08997301, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 300  ,Loss: tf.Tensor(0.08967749, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 400  ,Loss: tf.Tensor(0.08994738, shape=(), dtype=float32)\n",
      "Epoch: 26 ,Accuracy: 0.1136\n",
      "Epoch: 27  Step: 0  ,Loss: tf.Tensor(0.089674234, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 100  ,Loss: tf.Tensor(0.089946136, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 200  ,Loss: tf.Tensor(0.08997218, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 300  ,Loss: tf.Tensor(0.089676194, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 400  ,Loss: tf.Tensor(0.089947335, shape=(), dtype=float32)\n",
      "Epoch: 27 ,Accuracy: 0.1136\n",
      "Epoch: 28  Step: 0  ,Loss: tf.Tensor(0.0896731, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 100  ,Loss: tf.Tensor(0.089945346, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 200  ,Loss: tf.Tensor(0.08997147, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 300  ,Loss: tf.Tensor(0.089675136, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 400  ,Loss: tf.Tensor(0.08994723, shape=(), dtype=float32)\n",
      "Epoch: 28 ,Accuracy: 0.1136\n",
      "Epoch: 29  Step: 0  ,Loss: tf.Tensor(0.08967213, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 100  ,Loss: tf.Tensor(0.08994466, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 200  ,Loss: tf.Tensor(0.08997082, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 300  ,Loss: tf.Tensor(0.08967423, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 400  ,Loss: tf.Tensor(0.08994707, shape=(), dtype=float32)\n",
      "Epoch: 29 ,Accuracy: 0.1136\n"
     ]
    }
   ],
   "source": [
    "# 科学技术法表示的学习率\n",
    "lr = 1e-5\n",
    "# 可以直接使用for(x,y) in tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "# 不需要转化为迭代器\n",
    "for epoch in range(30):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        # 先将图片打平(维度转变)\n",
    "        x = tf.reshape(tf.cast(x,tf.float32),[-1,28*28])/255.\n",
    "    #     print(tf.matmul(x,w1).shape)\n",
    "        # 标志位转化为10位的one-hot形式的tensor\n",
    "        y = tf.one_hot(y,depth=10)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 将所有的梯度计算加到这个context中\n",
    "\n",
    "            # 第一层前向传播\n",
    "            # 这里b1虽然是tf.ones([512])大小的, 但是系统会自动完成broadingcast之后再进行相加\n",
    "            h1 = tf.matmul(x,w1) + b1\n",
    "\n",
    "            # 进行relu转换\n",
    "            h1 = tf.nn.relu(h1)\n",
    "\n",
    "            # 第二层前向传播\\\n",
    "            h2 = tf.matmul(h1,w2) + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "\n",
    "            # 第三层前向传播\n",
    "            output = tf.matmul(h2,w3) + b3\n",
    "    #         print(output.shape)\n",
    "    #         print(y.shape)\n",
    "\n",
    "    #         print(output.shape)\n",
    "\n",
    "            #计算误差\n",
    "            mse_loss = tf.reduce_mean(tf.square(output - y))\n",
    "            if step%100 == 0:\n",
    "                print('Epoch:',epoch,' Step:',step,' ,Loss:', mse_loss)\n",
    "        \n",
    "        grads = tape.gradient(mse_loss,[w1,b1,w2,b2,w3,b3])\n",
    "        # 获取对应的每个参量的梯度信息\n",
    "    #     print(grads)\n",
    "        # 进行梯度优化\n",
    "\n",
    "        # 这里如果直接写w1 = w1 - lr*grads[0], 剪发操作之后的w1被赋值成了一个tfTensor的对象\n",
    "        # 这样的Tensor对象下一次在求带图中又将会返回一个None的对象, 所以会报错\n",
    "        # 针对这种情况我们使用w1.assign_sub()方法,这样使用原地更新的方式减去要更新的值\n",
    "        # w1的属性不会变成Tensor,还会保持是一个tf.Variable对象\n",
    "        w1.assign_sub(lr*grads[0])\n",
    "        b1.assign_sub(lr*grads[1])\n",
    "        w2.assign_sub(lr*grads[2])\n",
    "        b2.assign_sub(lr*grads[3])\n",
    "        w3.assign_sub(lr*grads[4])\n",
    "        b3.assign_sub(lr*grads[5])\n",
    "        # 这里的0对应tape.gradient(mse_loss,[w1,b1,w2,b2,w3,b3])中的第0个位置上的参数\n",
    "    \n",
    "    correct_sum = 0\n",
    "    total = 0\n",
    "    for step,(x,y) in enumerate(test_db):\n",
    "        y = tf.cast(y,dtype=tf.int32)\n",
    "        x = tf.cast(tf.reshape(x,[-1,28*28]),dtype=tf.float32)/255.\n",
    "        h1 = tf.nn.relu(x@w1+b1)\n",
    "        h2 = tf.nn.relu(h1@w2+b2)\n",
    "        out = h2@w3+b3 # out是一个b,10大小的矩阵\n",
    "        prod = tf.nn.softmax(out)# 进行softmax概率操作\n",
    "        pred = tf.cast(tf.argmax(prod,axis=1),dtype=tf.int32)# 获取最终最大概率的预测结果, 注意这里axis要是1\n",
    "#         print(pred)\n",
    "#         print(tf.equal(pred,y))\n",
    "        # 真实值是y, 需要与pred进行比较\n",
    "        correct = tf.reduce_sum(tf.cast(tf.equal(pred,y),dtype=tf.float16))\n",
    "        correct_sum += int(correct)\n",
    "#         print(int(correct),correct_sum)\n",
    "        total += x.shape[0]\n",
    "    print('Epoch:',epoch ,',Accuracy:', correct_sum/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
