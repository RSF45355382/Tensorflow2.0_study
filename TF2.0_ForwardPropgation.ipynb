{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets,optimizers\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (60000, 28, 28))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x,train_label),_ = datasets.mnist.load_data()\n",
    "train_label.shape, train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]), TensorShape([60000]), tf.float32, tf.int32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为tensor\n",
    "x = tf.convert_to_tensor(train_x,dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(train_label,dtype = tf.int32)\n",
    "x.shape, y.shape, x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(255.0, shape=(), dtype=float32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 查看最小值和最大值\n",
    "print(tf.reduce_min(x))\n",
    "print(tf.reduce_max(x))\n",
    "\n",
    "print(tf.reduce_max(y))\n",
    "print(tf.reduce_min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 28, 28]), TensorShape([128]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个数据集对象(实质是一个迭代器/生成器), 可以按照batch来取数据\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "# 转换为迭代器之后,获取下一个batch\n",
    "train_iter = iter(train_db)\n",
    "sample = train_iter.next()\n",
    "# 获得的sample是一个元组(x,y)的格式\n",
    "sample[0].shape, sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是[b,784] => [b,512] = > [b,256] => [b,10]\n",
    "# 转化为tf.Vatiable的目的是为了让tf.GradientTaps()能够跟踪\n",
    "# tf.GradientTaps()只能跟踪tfVariable的对象的梯度\n",
    "# 方差设定为0.1, 有助于网络收敛\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784,512],stddev = 0.1))\n",
    "b1 = tf.Variable(tf.ones([512]))\n",
    "\n",
    "w2 = tf.Variable(tf.random.truncated_normal([512,256],stddev = 0.1))\n",
    "b2 = tf.Variable(tf.ones([256]))\n",
    "\n",
    "w3 = tf.Variable(tf.random.truncated_normal([256,10],stddev = 0.1))\n",
    "b3 = tf.Variable(tf.ones([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Step: 0  ,Loss: tf.Tensor(105197.664, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 100  ,Loss: tf.Tensor(3055.8374, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 200  ,Loss: tf.Tensor(1482.2101, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 300  ,Loss: tf.Tensor(850.97675, shape=(), dtype=float32)\n",
      "Epoch: 0  Step: 400  ,Loss: tf.Tensor(614.9532, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 0  ,Loss: tf.Tensor(515.478, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 100  ,Loss: tf.Tensor(406.3272, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 200  ,Loss: tf.Tensor(283.44537, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 300  ,Loss: tf.Tensor(224.42447, shape=(), dtype=float32)\n",
      "Epoch: 1  Step: 400  ,Loss: tf.Tensor(165.29892, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 0  ,Loss: tf.Tensor(175.11203, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 100  ,Loss: tf.Tensor(147.23334, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 200  ,Loss: tf.Tensor(110.77246, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 300  ,Loss: tf.Tensor(105.20524, shape=(), dtype=float32)\n",
      "Epoch: 2  Step: 400  ,Loss: tf.Tensor(78.90444, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 0  ,Loss: tf.Tensor(96.32778, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 100  ,Loss: tf.Tensor(76.86544, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 200  ,Loss: tf.Tensor(58.602386, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 300  ,Loss: tf.Tensor(62.569725, shape=(), dtype=float32)\n",
      "Epoch: 3  Step: 400  ,Loss: tf.Tensor(47.28166, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 0  ,Loss: tf.Tensor(64.788925, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 100  ,Loss: tf.Tensor(49.320534, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 200  ,Loss: tf.Tensor(37.348274, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 300  ,Loss: tf.Tensor(43.499138, shape=(), dtype=float32)\n",
      "Epoch: 4  Step: 400  ,Loss: tf.Tensor(32.360928, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 0  ,Loss: tf.Tensor(48.77663, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 100  ,Loss: tf.Tensor(35.866184, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 200  ,Loss: tf.Tensor(26.678885, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 300  ,Loss: tf.Tensor(32.546017, shape=(), dtype=float32)\n",
      "Epoch: 5  Step: 400  ,Loss: tf.Tensor(23.77674, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 0  ,Loss: tf.Tensor(38.388214, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 100  ,Loss: tf.Tensor(27.933605, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 200  ,Loss: tf.Tensor(20.384068, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 300  ,Loss: tf.Tensor(25.779507, shape=(), dtype=float32)\n",
      "Epoch: 6  Step: 400  ,Loss: tf.Tensor(18.565056, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 0  ,Loss: tf.Tensor(31.334091, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 100  ,Loss: tf.Tensor(22.614553, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 200  ,Loss: tf.Tensor(16.051022, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 300  ,Loss: tf.Tensor(21.281885, shape=(), dtype=float32)\n",
      "Epoch: 7  Step: 400  ,Loss: tf.Tensor(15.163257, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 0  ,Loss: tf.Tensor(26.20846, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 100  ,Loss: tf.Tensor(18.874615, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 200  ,Loss: tf.Tensor(13.011096, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 300  ,Loss: tf.Tensor(18.00618, shape=(), dtype=float32)\n",
      "Epoch: 8  Step: 400  ,Loss: tf.Tensor(12.735229, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 0  ,Loss: tf.Tensor(22.534204, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 100  ,Loss: tf.Tensor(16.173244, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 200  ,Loss: tf.Tensor(10.848679, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 300  ,Loss: tf.Tensor(15.518346, shape=(), dtype=float32)\n",
      "Epoch: 9  Step: 400  ,Loss: tf.Tensor(10.938735, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 0  ,Loss: tf.Tensor(19.768566, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 100  ,Loss: tf.Tensor(14.110791, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 200  ,Loss: tf.Tensor(9.194207, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 300  ,Loss: tf.Tensor(13.615812, shape=(), dtype=float32)\n",
      "Epoch: 10  Step: 400  ,Loss: tf.Tensor(9.5612755, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 0  ,Loss: tf.Tensor(17.546862, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 100  ,Loss: tf.Tensor(12.507321, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 200  ,Loss: tf.Tensor(7.9128175, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 300  ,Loss: tf.Tensor(12.121117, shape=(), dtype=float32)\n",
      "Epoch: 11  Step: 400  ,Loss: tf.Tensor(8.475439, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 0  ,Loss: tf.Tensor(15.772696, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 100  ,Loss: tf.Tensor(11.207666, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 200  ,Loss: tf.Tensor(6.917174, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 300  ,Loss: tf.Tensor(10.906977, shape=(), dtype=float32)\n",
      "Epoch: 12  Step: 400  ,Loss: tf.Tensor(7.5715857, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 0  ,Loss: tf.Tensor(14.313429, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 100  ,Loss: tf.Tensor(10.125707, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 200  ,Loss: tf.Tensor(6.1301355, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 300  ,Loss: tf.Tensor(9.885191, shape=(), dtype=float32)\n",
      "Epoch: 13  Step: 400  ,Loss: tf.Tensor(6.8150773, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 0  ,Loss: tf.Tensor(13.0896, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 100  ,Loss: tf.Tensor(9.23163, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 200  ,Loss: tf.Tensor(5.5049825, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 300  ,Loss: tf.Tensor(9.027919, shape=(), dtype=float32)\n",
      "Epoch: 14  Step: 400  ,Loss: tf.Tensor(6.172872, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 0  ,Loss: tf.Tensor(12.034489, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 100  ,Loss: tf.Tensor(8.499502, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 200  ,Loss: tf.Tensor(4.9993796, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 300  ,Loss: tf.Tensor(8.29478, shape=(), dtype=float32)\n",
      "Epoch: 15  Step: 400  ,Loss: tf.Tensor(5.6209726, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 0  ,Loss: tf.Tensor(11.115873, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 100  ,Loss: tf.Tensor(7.8798156, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 200  ,Loss: tf.Tensor(4.5956917, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 300  ,Loss: tf.Tensor(7.6599336, shape=(), dtype=float32)\n",
      "Epoch: 16  Step: 400  ,Loss: tf.Tensor(5.146198, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 0  ,Loss: tf.Tensor(10.311293, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 100  ,Loss: tf.Tensor(7.3382125, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 200  ,Loss: tf.Tensor(4.244216, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 300  ,Loss: tf.Tensor(7.1033926, shape=(), dtype=float32)\n",
      "Epoch: 17  Step: 400  ,Loss: tf.Tensor(4.7349997, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 0  ,Loss: tf.Tensor(9.604944, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 100  ,Loss: tf.Tensor(6.8651605, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 200  ,Loss: tf.Tensor(3.9369297, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 300  ,Loss: tf.Tensor(6.6187897, shape=(), dtype=float32)\n",
      "Epoch: 18  Step: 400  ,Loss: tf.Tensor(4.3756194, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 0  ,Loss: tf.Tensor(8.979525, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 100  ,Loss: tf.Tensor(6.4486136, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 200  ,Loss: tf.Tensor(3.6693, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 300  ,Loss: tf.Tensor(6.195876, shape=(), dtype=float32)\n",
      "Epoch: 19  Step: 400  ,Loss: tf.Tensor(4.0699186, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 0  ,Loss: tf.Tensor(8.421199, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 100  ,Loss: tf.Tensor(6.071575, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 200  ,Loss: tf.Tensor(3.4354362, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 300  ,Loss: tf.Tensor(5.8186846, shape=(), dtype=float32)\n",
      "Epoch: 20  Step: 400  ,Loss: tf.Tensor(3.801262, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 0  ,Loss: tf.Tensor(7.916069, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 100  ,Loss: tf.Tensor(5.733513, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 200  ,Loss: tf.Tensor(3.2275033, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 300  ,Loss: tf.Tensor(5.484603, shape=(), dtype=float32)\n",
      "Epoch: 21  Step: 400  ,Loss: tf.Tensor(3.5597782, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 0  ,Loss: tf.Tensor(7.4519844, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 100  ,Loss: tf.Tensor(5.4312143, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22  Step: 200  ,Loss: tf.Tensor(3.0417092, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 300  ,Loss: tf.Tensor(5.1872606, shape=(), dtype=float32)\n",
      "Epoch: 22  Step: 400  ,Loss: tf.Tensor(3.3415215, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 0  ,Loss: tf.Tensor(7.025429, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 100  ,Loss: tf.Tensor(5.16039, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 200  ,Loss: tf.Tensor(2.8752143, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 300  ,Loss: tf.Tensor(4.9195814, shape=(), dtype=float32)\n",
      "Epoch: 23  Step: 400  ,Loss: tf.Tensor(3.141169, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 0  ,Loss: tf.Tensor(6.6309767, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 100  ,Loss: tf.Tensor(4.916455, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 200  ,Loss: tf.Tensor(2.7241468, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 300  ,Loss: tf.Tensor(4.6764956, shape=(), dtype=float32)\n",
      "Epoch: 24  Step: 400  ,Loss: tf.Tensor(2.9586287, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 0  ,Loss: tf.Tensor(6.2744503, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 100  ,Loss: tf.Tensor(4.6978273, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 200  ,Loss: tf.Tensor(2.5852618, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 300  ,Loss: tf.Tensor(4.45643, shape=(), dtype=float32)\n",
      "Epoch: 25  Step: 400  ,Loss: tf.Tensor(2.791668, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 0  ,Loss: tf.Tensor(5.9426622, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 100  ,Loss: tf.Tensor(4.5012684, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 200  ,Loss: tf.Tensor(2.4577546, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 300  ,Loss: tf.Tensor(4.2611027, shape=(), dtype=float32)\n",
      "Epoch: 26  Step: 400  ,Loss: tf.Tensor(2.6393158, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 0  ,Loss: tf.Tensor(5.633509, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 100  ,Loss: tf.Tensor(4.322529, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 200  ,Loss: tf.Tensor(2.3403177, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 300  ,Loss: tf.Tensor(4.086602, shape=(), dtype=float32)\n",
      "Epoch: 27  Step: 400  ,Loss: tf.Tensor(2.5000622, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 0  ,Loss: tf.Tensor(5.34863, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 100  ,Loss: tf.Tensor(4.157596, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 200  ,Loss: tf.Tensor(2.2322445, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 300  ,Loss: tf.Tensor(3.9278793, shape=(), dtype=float32)\n",
      "Epoch: 28  Step: 400  ,Loss: tf.Tensor(2.3723283, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 0  ,Loss: tf.Tensor(5.0844865, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 100  ,Loss: tf.Tensor(4.007159, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 200  ,Loss: tf.Tensor(2.1323237, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 300  ,Loss: tf.Tensor(3.7824066, shape=(), dtype=float32)\n",
      "Epoch: 29  Step: 400  ,Loss: tf.Tensor(2.2545528, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 科学技术法表示的学习率\n",
    "lr = 1e-6\n",
    "# 可以直接使用for(x,y) in tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "# 不需要转化为迭代器\n",
    "for epoch in range(30):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        # 先将图片打平(维度转变)\n",
    "        x = tf.reshape(x,[-1,28*28])\n",
    "    #     print(tf.matmul(x,w1).shape)\n",
    "        # 标志位转化为10位的one-hot形式的tensor\n",
    "        y = tf.one_hot(y,depth=10)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 将所有的梯度计算加到这个context中\n",
    "\n",
    "            # 第一层前向传播\n",
    "            # 这里b1虽然是tf.ones([512])大小的, 但是系统会自动完成broadingcast之后再进行相加\n",
    "            h1 = tf.matmul(x,w1) + b1\n",
    "\n",
    "            # 进行relu转换\n",
    "            h1 = tf.nn.relu(h1)\n",
    "\n",
    "            # 第二层前向传播\\\n",
    "            h2 = tf.matmul(h1,w2) + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "\n",
    "            # 第三层前向传播\n",
    "            output = tf.matmul(h2,w3) + b3\n",
    "    #         print(output.shape)\n",
    "    #         print(y.shape)\n",
    "\n",
    "    #         print(output.shape)\n",
    "\n",
    "            #计算误差\n",
    "            mse_loss = tf.reduce_mean(tf.square(output - y))\n",
    "            if step%100 == 0:\n",
    "                print('Epoch:',epoch,' Step:',step,' ,Loss:', mse_loss)\n",
    "\n",
    "        grads = tape.gradient(mse_loss,[w1,b1,w2,b2,w3,b3])\n",
    "        # 获取对应的每个参量的梯度信息\n",
    "    #     print(grads)\n",
    "        # 进行梯度优化\n",
    "\n",
    "        # 这里如果直接写w1 = w1 - lr*grads[0], 剪发操作之后的w1被赋值成了一个tfTensor的对象\n",
    "        # 这样的Tensor对象下一次在求带图中又将会返回一个None的对象, 所以会报错\n",
    "        # 针对这种情况我们使用w1.assign_sub()方法,这样使用原地更新的方式减去要更新的值\n",
    "        # w1的属性不会变成Tensor,还会保持是一个tf.Variable对象\n",
    "        w1.assign_sub(lr*grads[0])\n",
    "        b1.assign_sub(lr*grads[1])\n",
    "        w2.assign_sub(lr*grads[2])\n",
    "        b2.assign_sub(lr*grads[3])\n",
    "        w3.assign_sub(lr*grads[4])\n",
    "        b3.assign_sub(lr*grads[5])\n",
    "        # 这里的0对应tape.gradient(mse_loss,[w1,b1,w2,b2,w3,b3])中的第0个位置上的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
