{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(imgs,name):\n",
    "    new_img = Image.new('L',(280,280))\n",
    "    index = 0\n",
    "    for i in range(0,280,28):\n",
    "        for j in range(0,280,28):\n",
    "            im = imgs[index]\n",
    "            im = Image.fromarray(im,mode='L')\n",
    "            new_img.paste(im,(i,j))\n",
    "            index += 1\n",
    "            \n",
    "    new_img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数定义\n",
    "h_dim = 20  #最终降维之后的维度\n",
    "batchsz = 512\n",
    "learning_rate = 1e-3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255.\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data,train_label),(test_data,test_label) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "db = db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices(test_data)\n",
    "test_db = test_db.map(preprocess).batch(batchsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自编码器不需要label(无监督学习)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "    def __init__(self,h_dim):  # h_dim是中间隐藏层的维度\n",
    "        super(AE,self).__init__()\n",
    "        # 首先定义编码器\n",
    "        self.encoder = keras.Sequential([\n",
    "            keras.layers.Dense(256,activation = tf.nn.relu,),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(128,activation = tf.nn.relu,),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(h_dim),\n",
    "        ])\n",
    "        \n",
    "        # 定义解码器\n",
    "        self.decoder = keras.Sequential([\n",
    "            keras.layers.Dense(128,activation = tf.nn.relu,),\n",
    "#             keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(256,activation = tf.nn.relu,),\n",
    "#             keras.layers.Dropout(0.4),\n",
    "            keras.layers.Dense(784),\n",
    "        ])\n",
    "    \n",
    "    def call(self,inputs,training = None):\n",
    "        # 首先编码成隐藏层数据\n",
    "        h = self.encoder(inputs)\n",
    "        \n",
    "        # 接下来进行解码\n",
    "        x_hat = self.decoder(h)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_18 (Sequential)   multiple                  236436    \n",
      "_________________________________________________________________\n",
      "sequential_19 (Sequential)   multiple                  237200    \n",
      "=================================================================\n",
      "Total params: 473,636\n",
      "Trainable params: 473,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AE(h_dim)\n",
    "model.build(input_shape = (None,784))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.69376504\n",
      "0 100 0.33426696\n",
      "1 0 0.31869346\n",
      "1 100 0.30915943\n",
      "2 0 0.30374634\n",
      "2 100 0.30402866\n",
      "3 0 0.2960075\n",
      "3 100 0.2879151\n",
      "4 0 0.29201528\n",
      "4 100 0.29691324\n",
      "5 0 0.28097254\n",
      "5 100 0.29715574\n",
      "6 0 0.2888335\n",
      "6 100 0.29048067\n",
      "7 0 0.2889262\n",
      "7 100 0.28994003\n",
      "8 0 0.28304884\n",
      "8 100 0.2860364\n",
      "9 0 0.28172478\n",
      "9 100 0.28562355\n",
      "10 0 0.28953028\n",
      "10 100 0.2882984\n",
      "11 0 0.2820677\n",
      "11 100 0.27415124\n",
      "12 0 0.28383937\n",
      "12 100 0.27891284\n",
      "13 0 0.28188974\n",
      "13 100 0.28092182\n",
      "14 0 0.27767718\n",
      "14 100 0.27877706\n",
      "15 0 0.2807819\n",
      "15 100 0.27653626\n",
      "16 0 0.2805609\n",
      "16 100 0.2820426\n",
      "17 0 0.2788326\n",
      "17 100 0.27664763\n",
      "18 0 0.27883774\n",
      "18 100 0.2836342\n",
      "19 0 0.27100262\n",
      "19 100 0.27202377\n",
      "20 0 0.26786596\n",
      "20 100 0.28971845\n",
      "21 0 0.2826934\n",
      "21 100 0.28230736\n",
      "22 0 0.27376607\n",
      "22 100 0.27023262\n",
      "23 0 0.2802124\n",
      "23 100 0.27545622\n",
      "24 0 0.270912\n",
      "24 100 0.27445\n",
      "25 0 0.27591082\n",
      "25 100 0.27804992\n",
      "26 0 0.27442777\n",
      "26 100 0.27175453\n",
      "27 0 0.26143324\n",
      "27 100 0.27107704\n",
      "28 0 0.27394733\n",
      "28 100 0.27833396\n",
      "29 0 0.27253962\n",
      "29 100 0.28026158\n",
      "30 0 0.2689855\n",
      "30 100 0.2739426\n",
      "31 0 0.27022636\n",
      "31 100 0.27899837\n",
      "32 0 0.2791758\n",
      "32 100 0.27124992\n",
      "33 0 0.2673441\n",
      "33 100 0.28250065\n",
      "34 0 0.26907566\n",
      "34 100 0.27573913\n",
      "35 0 0.26479378\n",
      "35 100 0.2714455\n",
      "36 0 0.2723268\n",
      "36 100 0.27495205\n",
      "37 0 0.27447712\n",
      "37 100 0.26774785\n",
      "38 0 0.269973\n",
      "38 100 0.27294102\n",
      "39 0 0.27407432\n",
      "39 100 0.27176762\n",
      "40 0 0.2681736\n",
      "40 100 0.26853824\n",
      "41 0 0.27243078\n",
      "41 100 0.26610848\n",
      "42 0 0.27253944\n",
      "42 100 0.27444035\n",
      "43 0 0.27568114\n",
      "43 100 0.27707446\n",
      "44 0 0.27749246\n",
      "44 100 0.27274513\n",
      "45 0 0.27147764\n",
      "45 100 0.2699743\n",
      "46 0 0.2677648\n",
      "46 100 0.27536154\n",
      "47 0 0.2737584\n",
      "47 100 0.2699492\n",
      "48 0 0.26905364\n",
      "48 100 0.26897722\n",
      "49 0 0.2675127\n",
      "49 100 0.27502152\n",
      "50 0 0.2696465\n",
      "50 100 0.26554558\n",
      "51 0 0.26916218\n",
      "51 100 0.26630312\n",
      "52 0 0.2732004\n",
      "52 100 0.27092552\n",
      "53 0 0.26354408\n",
      "53 100 0.27209765\n",
      "54 0 0.2716895\n",
      "54 100 0.2748204\n",
      "55 0 0.26906753\n",
      "55 100 0.2622603\n",
      "56 0 0.26906765\n",
      "56 100 0.27270782\n",
      "57 0 0.27509904\n",
      "57 100 0.2785611\n",
      "58 0 0.26505393\n",
      "58 100 0.27365845\n",
      "59 0 0.27461737\n",
      "59 100 0.26825097\n",
      "60 0 0.2663887\n",
      "60 100 0.27189797\n",
      "61 0 0.27031407\n",
      "61 100 0.2703337\n",
      "62 0 0.26950318\n",
      "62 100 0.26886505\n",
      "63 0 0.2774638\n",
      "63 100 0.2652542\n",
      "64 0 0.26488423\n",
      "64 100 0.2713762\n",
      "65 0 0.26493558\n",
      "65 100 0.28413174\n",
      "66 0 0.2710322\n",
      "66 100 0.2718177\n",
      "67 0 0.27145118\n",
      "67 100 0.27785453\n",
      "68 0 0.27135065\n",
      "68 100 0.27837107\n",
      "69 0 0.27630717\n",
      "69 100 0.27554715\n",
      "70 0 0.26875806\n",
      "70 100 0.2736526\n",
      "71 0 0.27279484\n",
      "71 100 0.27433833\n",
      "72 0 0.268606\n",
      "72 100 0.27281338\n",
      "73 0 0.2694794\n",
      "73 100 0.26943478\n",
      "74 0 0.26933983\n",
      "74 100 0.27388188\n",
      "75 0 0.26358443\n",
      "75 100 0.26992565\n",
      "76 0 0.2669692\n",
      "76 100 0.27914223\n",
      "77 0 0.27282214\n",
      "77 100 0.27449632\n",
      "78 0 0.27527416\n",
      "78 100 0.27901426\n",
      "79 0 0.2768286\n",
      "79 100 0.27581224\n",
      "80 0 0.27457485\n",
      "80 100 0.2772812\n",
      "81 0 0.27423608\n",
      "81 100 0.27272803\n",
      "82 0 0.27094185\n",
      "82 100 0.27791208\n",
      "83 0 0.2619234\n",
      "83 100 0.27342886\n",
      "84 0 0.27204752\n",
      "84 100 0.27278337\n",
      "85 0 0.27172685\n",
      "85 100 0.2699001\n",
      "86 0 0.2634441\n",
      "86 100 0.26524264\n",
      "87 0 0.27190018\n",
      "87 100 0.26613218\n",
      "88 0 0.2739655\n",
      "88 100 0.27432144\n",
      "89 0 0.2604789\n",
      "89 100 0.26983738\n",
      "90 0 0.2660016\n",
      "90 100 0.28230944\n",
      "91 0 0.2680041\n",
      "91 100 0.27103943\n",
      "92 0 0.27281082\n",
      "92 100 0.27195415\n",
      "93 0 0.2694646\n",
      "93 100 0.27411437\n",
      "94 0 0.27469498\n",
      "94 100 0.2686681\n",
      "95 0 0.262554\n",
      "95 100 0.2729944\n",
      "96 0 0.27357802\n",
      "96 100 0.27097365\n",
      "97 0 0.26619947\n",
      "97 100 0.27189574\n",
      "98 0 0.25974223\n",
      "98 100 0.2712941\n",
      "99 0 0.27297142\n",
      "99 100 0.27280867\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for step,x in enumerate(db):\n",
    "        x = tf.reshape(x,[-1,784])\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_hat_logits = model(x)\n",
    "            rec_loss = tf.losses.binary_crossentropy(x,x_hat_logits,from_logits=True)\n",
    "            rec_loss = tf.reduce_mean(rec_loss)\n",
    "        grads = tape.gradient(rec_loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    \n",
    "        if step%100 == 0:\n",
    "            print(epoch,step,rec_loss.numpy())\n",
    "    \n",
    "    # 检验模型\n",
    "    x = next(iter(test_db))\n",
    "    x = tf.reshape(x,[-1,784])\n",
    "    logits = model(x)\n",
    "    x_hat = tf.sigmoid(logits)\n",
    "    \n",
    "    x_hat = tf.reshape(x_hat,[-1,28,28])\n",
    "    \n",
    "    # 显式输出结果,保存文件\n",
    "    x = tf.reshape(x,[-1,28,28])\n",
    "    x_orig = x.numpy()*255. \n",
    "    x_orig = x_orig.astype(np.uint8)\n",
    "    \n",
    "    x_got = x_hat.numpy()*255. \n",
    "    x_got = x_got.astype(np.uint8)\n",
    "    save_image(x_orig,r'./image/{}_orig.png'.format(epoch))\n",
    "    save_image(x_got,r'./image/{}_got.png'.format(epoch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
