{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.linspace(-6.,6.,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13, shape=(10,), dtype=float32, numpy=\n",
       "array([0.00247264, 0.00931597, 0.03444517, 0.11920291, 0.33924365,\n",
       "       0.6607564 , 0.8807971 , 0.96555483, 0.99068403, 0.9975274 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigmoid函数将数据归一化到0到1之间 \n",
    "\n",
    "tf.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(10,), dtype=float32, numpy=\n",
       "array([4.5246225e-06, 1.7164924e-05, 6.5118002e-05, 2.4703599e-04,\n",
       "       9.3717274e-04, 3.5553225e-03, 1.3487710e-02, 5.1167920e-02,\n",
       "       1.9411403e-01, 7.3640394e-01], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # 将所有节点数据归一化到0到1并保证所有节点的值之和为1\n",
    "    tf.nn.softmax(a)\n",
    "    # 输出的所有的值都在0到1之间, 而且所有值的和为1\n",
    "    \n",
    "    # 这个函数可以方法数据中的大小比值, 打的更大, 小的更小, 所以叫softmax(软性放大 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ 0.22111034, -1.7015052 ,  0.77100945,  0.09290552,  1.5321136 ,\n",
       "        -0.37176895, -0.5335989 ,  1.7109485 ,  1.780788  , -0.7167311 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sample = tf.random.uniform([1,10],minval=-2,maxval=2)\n",
    " sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30, shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.05531926, 0.00808901, 0.09587261, 0.04866287, 0.20522858,\n",
       "        0.03057681, 0.0260082 , 0.24541712, 0.26316965, 0.02165594]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 另一种方法, tanh, 将数据保证在-1到1之间\n",
    "b = tf.range(-2.,3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(5,), dtype=float32, numpy=\n",
       "array([-0.9640276, -0.7615942,  0.       ,  0.7615942,  0.9640276],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tanh(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
